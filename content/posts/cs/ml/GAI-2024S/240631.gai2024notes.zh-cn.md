---
title: "LLM Benchmark & Safety"
date: 2024-06-30T10:00:00+08:00
summary: "Generative AI 2024 Spring 课程笔记"
draft: false

categories: ["Machine Learning"]
tags: ["notes", "LLM", "Benchmark", "Safety"]

cover: "https://pic.aspi-rin.top/2025/09/166ba96b40200403d513b0718aa60533.jpg"

showLicense: true
showRelated: true

---

## 语言模型能力检定 Benchmark

### [MMLU](https://arxiv.org/abs/2009.03300)

选择题，包括初等数学、美国历史、计算机科学、法律等 57 项任务

![](https://pic.aspi-rin.top/2025/07/eb61a1b5c5eb56f692421c88dc1d2fdd.jpg)

### [Arena](https://lmarena.ai/leaderboard) 排行榜

![](https://pic.aspi-rin.top/2025/07/9d9397857b83b05753c62b8c2c26df06.jpg)

用更强大的语言模型来评估结果是否正确

### [MT-Bench](https://arxiv.org/abs/2306.05685)

只有 80 题，无标准答案，用 GPT-4 衡量

- 可能存在偏见：语言模型喜欢长的答案

### [arena-hard](https://lmsys.org/blog/2024-04-19-arena-hard/)

MT-Bench 的改进

### [Big Bench](https://arxiv.org/abs/2206.04615)

包含 204 个任务，覆盖语言学、数学、常识推理、生物、物理、社会偏见等领域，任务难度超越当前模型的已知能力

Emoji Movie

👧🐟🐠🐡 - *Finding Nemo*
👦👓⚡️ - *Harry Potter*

Checkmate In One Move

```Plain
1. e4 e6 2. Ke2 d5 3. e5 c5 4. f4 Nc6              
2. Nf3 Qb6 6. g4 Bd7 7. h4 Nge7 8. c3 Ng6          
3. d4 cxd4 10. cxd4 Be7 11. Kf2 O-O 12. h5 Nh8          ----------->   Bxh7#
4. Be3 Qxb2+ 14. Kg3 Qxa1 15. Bd3 Qxa2 16. Rh2 Qa1
5. Qc2 Nb4 18.               
```

ASCII word recognition

![BENCH](https://pic.aspi-rin.top/2025/07/93cd620dbf42ac95e734ecd3561f17e9.jpg)

![](https://pic.aspi-rin.top/2025/07/ae75273e5787426ce43f932b6ea9c074.jpg)


### [大海捞针](https://github.com/gkamradt/LLMTest_NeedleInAHaystack) 测试阅读长文本的能力

将一个随机事实（" 针 "）插入到长文本上下文（" 草堆 "）中，并测试模型能否正确检索这些信息

![](https://pic.aspi-rin.top/2025/07/13d3073d2b8d8c072a039616c53b7e80.jpg)

## LLM 的安全性

### LLM 会讲错话（Hallucination 幻觉）

事实核查：Gemini 在网络上找到相关内容背书

![Gemini 通过 Google 搜索核查结果](https://pic.aspi-rin.top/2025/07/c30720a624f038f7e5145780ea65598e.jpg)

### 模型的偏见/刻板印象

[GPT 认为亚洲人适合当金融分析师](https://www.bloomberg.com/graphics/2024-openai-gpt-hiring-racial-discrimination/)

![GPT 认为亚洲人适合当金融分析师](https://pic.aspi-rin.top/2025/07/481b943c91c5a4f118f53993e79e3ac6.jpg)

[对职业性别的刻板印象](https://textio.com/blog/chatgpt-writes-performance-feedback)

![](https://pic.aspi-rin.top/2025/07/a7fdfccf61f20c27636f4d7ce6005428.jpg)

[减轻偏见的方法](https://arxiv.org/abs/2309.00770)：调整输入数据，训练过程，推理过程，后处理

![在各个阶段消除偏见](https://pic.aspi-rin.top/2025/07/1a7e9c1aa7348d60d85c1b9bc38f6952.jpg)

### 这句话是不是 LLM 生成的？

寻找人类和 AI 的文本的差异

- [估算文本的内在维度（Intrinsic Dimension, ID）](https://arxiv.org/abs/2306.04723)
训练分类器区分人类和 AI 生成的文字
- [Testing of Detection Tools for AI-Generated Text](https://arxiv.org/abs/2306.15666)
在语言模型的输出上加浮水印
- LeftHash, SelfHash 等方法
- 主流方法是在语言模型生成每个 token 时，稍微调整生成概率，使得部分词出现的频率略高于正常情况
- [论大型语言模型水印的可靠性](https://arxiv.org/abs/2306.04634)

### LLM 也会被骗 - Prompt Hacking

Jailbreaking - 越狱提示，攻击模型本身，让它说出不该讲的话

- 对应到人类：杀人放火

Prompt Injection 攻击基于语言模型的应用，让它在不恰当的时机做不恰当的事

- 对应到人类：上课时突然唱歌

#### Jailbreaking

DAN - Do Anything Now

[https://arxiv.org/abs/2308.03825](https://arxiv.org/abs/2308.03825)

![](https://pic.aspi-rin.top/2025/07/7b99e62a7fcf8709f3468bf62726134d.jpg)

- 使用模型不是很熟悉的语言 [https://arxiv.org/abs/2307.02483](https://arxiv.org/abs/2307.02483)
- 给予冲突的指令 [https://arxiv.org/abs/2307.02483](https://arxiv.org/abs/2307.02483)

    ![](https://pic.aspi-rin.top/2025/07/43411578ca59840b22864c1a13502484.jpg)

- 视图说服语言模型（如编一个故事）
- 让语言模型讲出训练资料

    ![](https://pic.aspi-rin.top/2025/07/b8acfb229aecbe6c3cc2c298d2efd2f7.jpg)

#### Prompt Injection

![](https://pic.aspi-rin.top/2025/07/61ff7fc39d90eef7a3ee31f8db9a3049.jpg)

[Prompt Injection 比赛](https://arxiv.org/pdf/2311.16119) 让语言模型忘记给定的角色，说出 'I have been PWNED’

![](https://pic.aspi-rin.top/2025/07/e9608db5e43626be3d7749d2eae58aee.jpg)
